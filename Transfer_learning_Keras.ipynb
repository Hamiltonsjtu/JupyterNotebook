{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import keras\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "#\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse  #这个模块是命令行参数传入，在nb中不需要\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define global variable\n",
    "IM_WIDTH, IM_HEIGHT = 299, 299    #修正 InceptionV3 的尺寸参数\n",
    "EPOCHS = 50\n",
    "WORKERS = 6\n",
    "BAT_SIZE = 24\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172 #微调需要传递的参数\n",
    "CLASSES_NUM = 3\n",
    "# end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGenerator = ImageDataGenerator(\n",
    "                                rotation_range=30, \n",
    "                                width_shift_range=0.2, \n",
    "                                channel_shift_range=0.2,\n",
    "                                height_shift_range=0.2, \n",
    "                                shear_range=0.1, \n",
    "                                zoom_range=0.2,  \n",
    "                                brightness_range=[0.8, 1.2], \n",
    "                                horizontal_flip=True, \n",
    "                                vertical_flip=True, \n",
    "                                fill_mode=\"constant\", \n",
    "                                cval=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(pic_dir, file_type):\n",
    "    ret_list = []\n",
    "    for file in os.listdir(pic_dir):\n",
    "        if not file.lower().endswith(file_type.lower()):\n",
    "            continue\n",
    "        ret_list.append(pic_dir + file)\n",
    "    return ret_list\n",
    "#定义一个方法——获取训练集和验证集中的样本数量，即nb_train_samples, nb_val_samples\n",
    "def get_nb_files(directory):\n",
    "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\"))) # glob模块是用来查找匹配文件的，后面接匹配规则。\n",
    "    return cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义增加最后一个全连接层的函数\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "\n",
    "    Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    #debug\n",
    "    x = Dropout(0.5)(x)\n",
    "    #end\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "    #predictions = Dense(nb_classes, activation='sigmoid')(x) #new softmax layer\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_to_transfer_learning(model,base_model):#base_model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "def setup_to_fine_tune(model,base_model):\n",
    "    GAP_LAYER = 17 # max_pooling_2d_2\n",
    "    for layer in base_model.layers[:GAP_LAYER+1]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[GAP_LAYER+1:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "def st_train(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    print(\"acc: \", acc)\n",
    "    print(\"val_acc: \", val_acc)\n",
    "    print(\"loss: \", loss)\n",
    "    print(\"val_loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_by_ratio(image, resize_w_h):\n",
    "    actual_h, actual_w = image.shape[0: -1]  #1920 1080\n",
    "    resize_h, resize_w = resize_w_h\n",
    "    scale_ratio = min(resize_w/actual_w, resize_h/actual_h)\n",
    "    scale_w = actual_w*scale_ratio #\n",
    "    scale_h = actual_h*scale_ratio  #\n",
    "    image = cv2.resize(image, (int(scale_w), int(scale_h)), interpolation = cv2.INTER_AREA)\n",
    "    new_image = np.zeros((resize_h, resize_w, 3), dtype='float32') # dtype='float32'uint8\n",
    "    try:\n",
    "        if scale_h == resize_h:\n",
    "            left_w = int((resize_w - int(scale_w))//2)\n",
    "            right_w = int(left_w + int(scale_w))\n",
    "            new_image[0:int(scale_h), left_w:right_w,  :] = image\n",
    "        else:\n",
    "            up_h = int((resize_h - int(scale_h))//2)\n",
    "            down_h = int(up_h + int(scale_h))\n",
    "            new_image[up_h:down_h, 0:int(scale_w),  :] = image\n",
    "        new_image = new_image.reshape(resize_h, resize_w, 3)\n",
    "        return new_image\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "def load_and_resize_image_(file):\n",
    "    img = cv2.imread(file) #open cv read as BGR\n",
    "    if len(img.shape) != 3 and img.shape[2] !=3:\n",
    "        img = None\n",
    "        return img\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #BGR to RGB\n",
    "    #img = cv2.resize(img, (IM_WIDTH, IM_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "    img = resize_image_by_ratio(img, (IM_WIDTH, IM_HEIGHT))\n",
    "    return img\n",
    "def load_and_resize_image_method2(file):\n",
    "    img1 = image.load_img(file)  # target_size参数前面是高\n",
    "    try:\n",
    "        img = img_to_array(img1)\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "        print(e)\n",
    "        return None\n",
    "    img = resize_image_by_ratio(img, (IM_WIDTH, IM_HEIGHT))\n",
    "    return img\n",
    "    \n",
    "def load_and_resize_image(file):\n",
    "    try:\n",
    "        img = cv2.imread(file)  # target_size参数前面是高\n",
    "        img_x1 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_x1 = img_x1.astype(np.float32)\n",
    "        '''img = image.load_img(file, target_size=(IMAGE_DIMS[0], IMAGE_DIMS[1]))  # target_size参数前面是高\n",
    "        img_x1 = img_to_array(img)'''\n",
    "        cols = img_x1.shape[1]\n",
    "        rows = img_x1.shape[0]\n",
    "\n",
    "        if rows > cols:\n",
    "            crop = cols\n",
    "            x_bias = 0\n",
    "            y_bias = int((rows - cols) / 2)\n",
    "        else:\n",
    "            crop = rows\n",
    "            y_bias = 0\n",
    "            x_bias = int((cols - rows) / 2)   \n",
    "        img_x2 = img_x1[y_bias:y_bias+crop][x_bias:x_bias+crop]\n",
    "        img_x2 = cv2.resize(img_x2, (IM_WIDTH, IM_HEIGHT), cv2.INTER_AREA)\n",
    "    except Exception as e:\n",
    "        img_x2 = None\n",
    "    return img_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(img_list, BAT_SIZE, gen_flag):\n",
    "    X_batch = []\n",
    "    Y_batch = []\n",
    "    Y_batch_onehot = []\n",
    "    label_int_list = []\n",
    "    if len(img_list) < BAT_SIZE:\n",
    "        raise \"image not enough\"\n",
    "    while True:\n",
    "        #print(img_list[0:10])\n",
    "        random.shuffle(img_list)\n",
    "        #print(img_list[0:10])\n",
    "        for img_file in img_list:\n",
    "            label_list = []\n",
    "            label_num = None\n",
    "            img = load_and_resize_image_method2(img_file)\n",
    "            if img is None:\n",
    "                continue\n",
    "            label_char = img_file.split('/')[-2]\n",
    "            if label_char == \"negative\":\n",
    "                label_num = 0\n",
    "                label_list = [1, 0, 0]\n",
    "            elif label_char == \"violence\":\n",
    "                label_num = 1\n",
    "                label_list = [0, 1, 0]\n",
    "            elif label_char == \"nsfw\":\n",
    "                label_num = 2\n",
    "                label_list = [0, 0, 1]\n",
    "            else:\n",
    "                continue\n",
    "            label_int_list.append(label_num)\n",
    "            X_batch.append(img)\n",
    "            Y_batch.append(label_list)\n",
    "            #generator\n",
    "            if gen_flag:\n",
    "                if label_num == 1 or label_num == 2:\n",
    "                    img_transf = imageGenerator.get_random_transform(img.shape)\n",
    "                    new_img = imageGenerator.apply_transform(img, img_transf)\n",
    "                    X_batch.append(new_img)\n",
    "                    Y_batch.append(label_list)\n",
    "                    label_int_list.append(label_num)\n",
    "#                print(\"len: X: \", len(X_batch))\n",
    "            #Y_batch_return = to_categorical(y_batch, 10) \n",
    "            if len(X_batch) >= BAT_SIZE:\n",
    "                X_batch = np.array(X_batch[0:BAT_SIZE], dtype='float32')/255.0\n",
    "                Y_batch = np.array(Y_batch[0:BAT_SIZE])\n",
    "                Y_batch_onehot = keras.utils.np_utils.to_categorical(label_int_list[0:BAT_SIZE], num_classes=CLASSES_NUM)\n",
    "#                 print(Y_batch)\n",
    "#                 print(\"len: Y: \", len(Y_batch_onehot))\n",
    "#                 print(Y_batch_onehot)\n",
    "#                 print(X_batch.shape)\n",
    "#                 print(X_batch)\n",
    "#                 print(\"center: \", X_batch[:, 100:120, 100:120, :])\n",
    "                yield (X_batch, Y_batch_onehot) #yield X_batch_return, Y_batch_return\n",
    "                X_batch = []\n",
    "                Y_batch = []\n",
    "                Y_batch_onehot = []\n",
    "                label_int_list = []\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_val_samples:  126\n",
      "total val samples:  126\n",
      "Found 682 images belonging to 3 classes.\n",
      "Found 126 images belonging to 3 classes.\n",
      "===val batch index:  0\n",
      "====val calss_indices:  {'nsfw': 1, 'negative': 0, 'violence': 2}\n",
      "start to transfer learning\n",
      "\n",
      "start to fine-tune\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Adagrad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-da8f43bc49f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;31m#     X, Y = batch_generator(train_img_list, BAT_SIZE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;31m#     print(Y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-da8f43bc49f9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_dir, val_dir, epochs, batch_size, restore_model_file)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'start to fine-tune\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;31m# fine-tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0msetup_to_fine_tune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_model_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_model_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-77f9e3ceeb49>\u001b[0m in \u001b[0;36msetup_to_fine_tune\u001b[1;34m(model, base_model)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mGAP_LAYER\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Adagrad' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(train_dir, val_dir, epochs=EPOCHS, batch_size=BAT_SIZE, restore_model_file=\"E:\\shuai\\weights-008.hdf5\"):\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "#     nb_train_samples = get_nb_files(train_dir)\n",
    "#     nb_classes = len(glob.glob(train_dir + \"/*\"))\n",
    "    class1_img_dir = train_dir + 'negative/'\n",
    "    class2_img_dir = train_dir + 'violence/'\n",
    "    class3_img_dir = train_dir + 'nsfw/'\n",
    "    train_negatives_img_list = sorted(get_all_files(class1_img_dir, '.jpg'))\n",
    "    train_negatives_img_list =  train_negatives_img_list + sorted(get_all_files(class1_img_dir, '.JPEG'))\n",
    "    \n",
    "    train_positives_vio_img_list = sorted(get_all_files(class2_img_dir, '.jpg'))\n",
    "    train_positives_vio_img_list = train_positives_vio_img_list + sorted(get_all_files(class2_img_dir, '.JPEG'))\n",
    "    \n",
    "    train_positives_nsfw_img_list = sorted(get_all_files(class3_img_dir, '.jpg'))\n",
    "    train_positives_nsfw_img_list = train_positives_nsfw_img_list + sorted(get_all_files(class3_img_dir, '.JPEG'))\n",
    "    \n",
    "    train_img_list = train_positives_vio_img_list + train_negatives_img_list + train_positives_nsfw_img_list\n",
    "    nb_train_samples = len(train_img_list)\n",
    "    \n",
    "    class1_img_dir_val = val_dir + 'negative/'\n",
    "    class2_img_dir_val = val_dir + 'violence/'\n",
    "    class3_img_dir_val = val_dir + 'nsfw/'\n",
    "    test_negatives_img_list = sorted(get_all_files(class1_img_dir_val, '.jpg'))\n",
    "    test_negatives_img_list =  test_negatives_img_list + sorted(get_all_files(class1_img_dir_val, '.JPEG'))\n",
    "    \n",
    "    test_positives_vio_img_list = sorted(get_all_files(class2_img_dir_val, '.jpg'))\n",
    "    test_positives_vio_img_list = test_positives_vio_img_list + sorted(get_all_files(class2_img_dir_val, '.JPEG'))\n",
    "    \n",
    "    test_positives_nsfw_img_list = sorted(get_all_files(class3_img_dir_val, '.jpg'))\n",
    "    test_positives_nsfw_img_list = test_positives_nsfw_img_list + sorted(get_all_files(class3_img_dir_val, '.JPEG'))\n",
    "    \n",
    "    test_img_list = test_positives_vio_img_list + test_negatives_img_list + test_positives_nsfw_img_list\n",
    "\n",
    "\n",
    "\n",
    "    nb_val_samples = get_nb_files(val_dir)\n",
    "    print('nb_val_samples: ', nb_val_samples)\n",
    "    print('total val samples: ', len(test_img_list))\n",
    "    epochs = int(epochs)\n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    # data prep\n",
    "    train_datagen =  ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = True,\n",
    "        seed=0\n",
    "    )\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = True,\n",
    "        seed=0\n",
    "    )\n",
    "    print(\"===val batch index: \", validation_generator.batch_index)\n",
    "    print(\"====val calss_indices: \", validation_generator.class_indices)\n",
    "    # 准备跑起来，首先给 base_model 和 model 赋值，迁移学习和微调都是使用 InceptionV3 的 notop 模型\n",
    "    #（看 inception_v3.py 源码，此模型是打开了最后一个全连接层），利用 add_new_last_layer 函数增加最后一个全连接层。\n",
    "\n",
    "    base_model = InceptionV3(include_top=False,weights='imagenet') #include_top=False excludes final FC layer\n",
    "    #base_model = InceptionV3(weights='./inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, CLASSES_NUM)\n",
    "\n",
    "    print('start to transfer learning\\n')\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learning(model, base_model)\n",
    "    print('start to fine-tune\\n')\n",
    "    # fine-tuning\n",
    "    setup_to_fine_tune(model,base_model)\n",
    "    if os.path.exists(restore_model_file):\n",
    "        model.load_weights(restore_model_file, by_name=True)\n",
    "        print('loaded weights')\n",
    "    \n",
    "    log_dir = './'\n",
    "    tensorboard = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + \"weights-{epoch:03d}.hdf5\",\n",
    "                                     monitor=\"val_loss\",\n",
    "                                     mode='min',\n",
    "                                     save_weights_only=False,\n",
    "                                     save_best_only=False, \n",
    "                                     verbose=1,\n",
    "                                     period=1)\n",
    "    callbacks_list = [checkpoint, tensorboard]\n",
    "    #model.fit()train_positives_img_list + train_negatives_img_list\n",
    "    t = 1 \n",
    "    class_weight={\n",
    "        0: 1,\n",
    "        1: len(train_negatives_img_list) / len(train_positives_vio_img_list) * t,\n",
    "        2: 1\n",
    "    }\n",
    "    print(class_weight)\n",
    "    random.seed(int(time.time()))\n",
    "    history_ft = model.fit_generator(\n",
    "        batch_generator(train_img_list, BAT_SIZE, True) ,  #batch_generator(train_dir + 'violence/', train_dir + 'no_violence/', BAT_SIZE), method2: train_generator \n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        workers=WORKERS,\n",
    "        use_multiprocessing=True,\n",
    "\tvalidation_data = batch_generator(test_img_list, 24, True),\n",
    "        #validation_data=validation_generator,##batch_generator(val_dir, BAT_SIZE)\n",
    "        validation_steps=nb_val_samples // batch_size,\n",
    "        class_weight=class_weight,  #class_weight = auto\n",
    "        callbacks=callbacks_list)\n",
    "    #model.save(output_model_file)\n",
    "    st_train(history_ft)\n",
    "    #plot_training(history_ft)\n",
    "\n",
    "def transform_label():\n",
    "    from sklearn.preprocessing import MultiLabelBinarizer\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    labels = [\n",
    "                (\"blue\", \"jeans\"),\n",
    "                (\"blue\", \"dress\"),\n",
    "                (\"red\", \"dress\"),\n",
    "                (\"red\", \"shirt\"),\n",
    "                (\"blue\", \"shirt\"),\n",
    "                (\"black\", \"jeans\")\n",
    "            ]\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    for (i, label) in enumerate(mlb.classes_):\n",
    "        print(\"{}. {}\".format(i + 1, label))\n",
    "        \n",
    "    label_one_hot = keras.utils.np_utils.to_categorical([0, 1], num_classes=3)#np_utils.to_categorical() utils.to_categorical\n",
    "    print(label_one_hot)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = 'e:/shuai/'\n",
    "#     root_dir = '/mnt/sda1/terry/data/'\n",
    "    train_dir = root_dir + 'train_data/'\n",
    "    val_dir = root_dir + 'test_data/'\n",
    "    retore_model_file = 'weights-050.hdf5'\n",
    "#     class1_img_dir = train_dir + 'violence/'\n",
    "#     class2_img_dir = train_dir + 'no_violence/'\n",
    "#     train_img_list =  sorted(get_all_files(class1_img_dir, '.jpg'))\n",
    "#     train_img_list = train_img_list + sorted(get_all_files(class1_img_dir, '.JPEG'))\n",
    "#     train_img_list = train_img_list + sorted(get_all_files(class2_img_dir, '.jpg'))\n",
    "#     train_img_list = train_img_list + sorted(get_all_files(class2_img_dir, '.JPEG'))\n",
    "#     X, Y = batch_generator(train_img_list, BAT_SIZE)\n",
    "#     print(Y)\n",
    "    train(train_dir, val_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Keras]",
   "language": "python",
   "name": "conda-env-Keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
